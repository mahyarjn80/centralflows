{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Singular Values Visualization for Dual Training Experiment\n",
        "\n",
        "This notebook visualizes the singular values of weight matrices from the dual training experiment comparing Shampoo and Muon optimizers.\n",
        "\n",
        "## Data Structure\n",
        "- **Log Directory**: `logs/dual_training_<uuid>/`\n",
        "- **Singular Values**: `singular_values_shampoo.pkl` and `singular_values_muon.pkl`\n",
        "- **Metrics**: `metrics_shampoo.npy` and `metrics_muon.npy`\n",
        "- **Config**: `config.pt`\n",
        "\n",
        "Each pickle file contains a list of tuples: `(step, sv_dict)` where:\n",
        "- `step`: training step number\n",
        "- `sv_dict`: dictionary mapping parameter names to their singular values (numpy arrays)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from typing import Dict, List, Tuple\n",
        "import pandas as pd\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Increase figure size and font size\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_latest_experiment():\n",
        "    \"\"\"Find the most recent dual training experiment.\"\"\"\n",
        "    logs_dir = Path('logs')\n",
        "    if not logs_dir.exists():\n",
        "        raise FileNotFoundError(\"No logs directory found. Please run the dual training experiment first.\")\n",
        "    \n",
        "    # Find all dual training directories\n",
        "    dual_dirs = list(logs_dir.glob('dual_training_*'))\n",
        "    if not dual_dirs:\n",
        "        raise FileNotFoundError(\"No dual training experiments found in logs directory.\")\n",
        "    \n",
        "    # Return the most recent one\n",
        "    latest_dir = max(dual_dirs, key=lambda x: x.stat().st_mtime)\n",
        "    print(f\"Using experiment directory: {latest_dir}\")\n",
        "    return latest_dir\n",
        "\n",
        "def load_experiment_data(exp_dir: Path):\n",
        "    \"\"\"Load all data from an experiment directory.\"\"\"\n",
        "    data = {}\n",
        "    \n",
        "    # Load singular values\n",
        "    shampoo_sv_path = exp_dir / 'singular_values_shampoo.pkl'\n",
        "    muon_sv_path = exp_dir / 'singular_values_muon.pkl'\n",
        "    \n",
        "    if shampoo_sv_path.exists():\n",
        "        with open(shampoo_sv_path, 'rb') as f:\n",
        "            data['singular_values_shampoo'] = pickle.load(f)\n",
        "    else:\n",
        "        print(f\"Warning: {shampoo_sv_path} not found\")\n",
        "    \n",
        "    if muon_sv_path.exists():\n",
        "        with open(muon_sv_path, 'rb') as f:\n",
        "            data['singular_values_muon'] = pickle.load(f)\n",
        "    else:\n",
        "        print(f\"Warning: {muon_sv_path} not found\")\n",
        "    \n",
        "    # Load metrics\n",
        "    shampoo_metrics_path = exp_dir / 'metrics_shampoo.npy'\n",
        "    muon_metrics_path = exp_dir / 'metrics_muon.npy'\n",
        "    \n",
        "    if shampoo_metrics_path.exists():\n",
        "        data['metrics_shampoo'] = np.load(shampoo_metrics_path, allow_pickle=True)\n",
        "    else:\n",
        "        print(f\"Warning: {shampoo_metrics_path} not found\")\n",
        "    \n",
        "    if muon_metrics_path.exists():\n",
        "        data['metrics_muon'] = np.load(muon_metrics_path, allow_pickle=True)\n",
        "    else:\n",
        "        print(f\"Warning: {muon_metrics_path} not found\")\n",
        "    \n",
        "    # Load config\n",
        "    config_path = exp_dir / 'config.pt'\n",
        "    if config_path.exists():\n",
        "        data['config'] = torch.load(config_path, map_location='cpu')\n",
        "    else:\n",
        "        print(f\"Warning: {config_path} not found\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Load the latest experiment\n",
        "exp_dir = find_latest_experiment()\n",
        "data = load_experiment_data(exp_dir)\n",
        "\n",
        "print(f\"Loaded data from: {exp_dir}\")\n",
        "print(f\"Available data keys: {list(data.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_data_overview(data):\n",
        "    \"\"\"Print overview of loaded data.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATA OVERVIEW\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Singular values\n",
        "    if 'singular_values_shampoo' in data:\n",
        "        sv_shampoo = data['singular_values_shampoo']\n",
        "        print(f\"Shampoo Singular Values: {len(sv_shampoo)} recordings\")\n",
        "        if sv_shampoo:\n",
        "            steps = [step for step, _ in sv_shampoo]\n",
        "            print(f\"  - Steps: {min(steps)} to {max(steps)} (every {steps[1]-steps[0] if len(steps)>1 else 'N/A'})\")\n",
        "            print(f\"  - Layers tracked: {len(sv_shampoo[0][1])}\")\n",
        "            print(f\"  - Layer names: {list(sv_shampoo[0][1].keys())}\")\n",
        "    \n",
        "    if 'singular_values_muon' in data:\n",
        "        sv_muon = data['singular_values_muon']\n",
        "        print(f\"Muon Singular Values: {len(sv_muon)} recordings\")\n",
        "        if sv_muon:\n",
        "            steps = [step for step, _ in sv_muon]\n",
        "            print(f\"  - Steps: {min(steps)} to {max(steps)} (every {steps[1]-steps[0] if len(steps)>1 else 'N/A'})\")\n",
        "            print(f\"  - Layers tracked: {len(sv_muon[0][1])}\")\n",
        "            print(f\"  - Layer names: {list(sv_muon[0][1].keys())}\")\n",
        "    \n",
        "    # Metrics\n",
        "    if 'metrics_shampoo' in data:\n",
        "        metrics_shampoo = data['metrics_shampoo']\n",
        "        print(f\"Shampoo Metrics: {len(metrics_shampoo)} epochs\")\n",
        "        print(f\"  - Columns: [epoch, train_loss, train_acc, test_loss, test_acc, lr]\")\n",
        "    \n",
        "    if 'metrics_muon' in data:\n",
        "        metrics_muon = data['metrics_muon']\n",
        "        print(f\"Muon Metrics: {len(metrics_muon)} epochs\")\n",
        "        print(f\"  - Columns: [epoch, train_loss, train_acc, test_loss, test_acc, lr]\")\n",
        "    \n",
        "    # Config\n",
        "    if 'config' in data:\n",
        "        config = data['config']\n",
        "        print(f\"Config: Available\")\n",
        "        if 'config' in config:\n",
        "            exp_config = config['config']\n",
        "            print(f\"  - Architecture: {exp_config.get('arch', 'Unknown')}\")\n",
        "            print(f\"  - Batch size: {exp_config.get('batch_size', 'Unknown')}\")\n",
        "            print(f\"  - Learning rates: Shampoo={exp_config.get('lr_filters_shampoo', 'Unknown')}, Muon={exp_config.get('lr_filters_muon', 'Unknown')}\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "\n",
        "print_data_overview(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Singular Value Evolution Over Time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_singular_value_evolution(data, layer_name=None, max_singular_values=10):\n",
        "    \"\"\"Plot evolution of singular values over training steps.\"\"\"\n",
        "    \n",
        "    shampoo_sv = data.get('singular_values_shampoo', [])\n",
        "    muon_sv = data.get('singular_values_muon', [])\n",
        "    \n",
        "    if not shampoo_sv or not muon_sv:\n",
        "        print(\"No singular value data available\")\n",
        "        return\n",
        "    \n",
        "    # Get available layers\n",
        "    available_layers = list(shampoo_sv[0][1].keys())\n",
        "    \n",
        "    if layer_name is None:\n",
        "        layer_name = available_layers[0]  # Use first layer\n",
        "    \n",
        "    if layer_name not in available_layers:\n",
        "        print(f\"Layer '{layer_name}' not found. Available layers: {available_layers}\")\n",
        "        return\n",
        "    \n",
        "    # Extract data for the specified layer\n",
        "    shampoo_steps = [step for step, _ in shampoo_sv]\n",
        "    shampoo_svs = [sv_dict[layer_name] for _, sv_dict in shampoo_sv]\n",
        "    \n",
        "    muon_steps = [step for step, _ in muon_sv]\n",
        "    muon_svs = [sv_dict[layer_name] for _, sv_dict in muon_sv]\n",
        "    \n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle(f'Singular Value Evolution: {layer_name}', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Plot top singular values\n",
        "    ax1 = axes[0, 0]\n",
        "    for i in range(min(max_singular_values, len(shampoo_svs[0]))):\n",
        "        shampoo_top_i = [sv[i] for sv in shampoo_svs]\n",
        "        ax1.plot(shampoo_steps, shampoo_top_i, label=f'σ{i+1}', alpha=0.8, linewidth=2)\n",
        "    ax1.set_title('Shampoo: Top Singular Values')\n",
        "    ax1.set_xlabel('Training Step')\n",
        "    ax1.set_ylabel('Singular Value')\n",
        "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_yscale('log')\n",
        "    \n",
        "    ax2 = axes[0, 1]\n",
        "    for i in range(min(max_singular_values, len(muon_svs[0]))):\n",
        "        muon_top_i = [sv[i] for sv in muon_svs]\n",
        "        ax2.plot(muon_steps, muon_top_i, label=f'σ{i+1}', alpha=0.8, linewidth=2)\n",
        "    ax2.set_title('Muon: Top Singular Values')\n",
        "    ax2.set_xlabel('Training Step')\n",
        "    ax2.set_ylabel('Singular Value')\n",
        "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_yscale('log')\n",
        "    \n",
        "    # Plot largest vs smallest singular values\n",
        "    ax3 = axes[1, 0]\n",
        "    shampoo_largest = [sv[0] for sv in shampoo_svs]\n",
        "    shampoo_smallest = [sv[-1] for sv in shampoo_svs]\n",
        "    ax3.plot(shampoo_steps, shampoo_largest, label='Largest σ', linewidth=3, color='red')\n",
        "    ax3.plot(shampoo_steps, shampoo_smallest, label='Smallest σ', linewidth=3, color='blue')\n",
        "    ax3.set_title('Shampoo: Largest vs Smallest')\n",
        "    ax3.set_xlabel('Training Step')\n",
        "    ax3.set_ylabel('Singular Value')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.set_yscale('log')\n",
        "    \n",
        "    ax4 = axes[1, 1]\n",
        "    muon_largest = [sv[0] for sv in muon_svs]\n",
        "    muon_smallest = [sv[-1] for sv in muon_svs]\n",
        "    ax4.plot(muon_steps, muon_largest, label='Largest σ', linewidth=3, color='red')\n",
        "    ax4.plot(muon_steps, muon_smallest, label='Smallest σ', linewidth=3, color='blue')\n",
        "    ax4.set_title('Muon: Largest vs Smallest')\n",
        "    ax4.set_xlabel('Training Step')\n",
        "    ax4.set_ylabel('Singular Value')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    ax4.set_yscale('log')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot for the first available layer\n",
        "if 'singular_values_shampoo' in data and data['singular_values_shampoo']:\n",
        "    available_layers = list(data['singular_values_shampoo'][0][1].keys())\n",
        "    print(f\"Available layers: {available_layers}\")\n",
        "    plot_singular_value_evolution(data, layer_name=available_layers[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Singular Value Distribution Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_singular_value_distributions(data, step_idx=-1):\n",
        "    \"\"\"Plot singular value distributions at a specific step.\"\"\"\n",
        "    \n",
        "    shampoo_sv = data.get('singular_values_shampoo', [])\n",
        "    muon_sv = data.get('singular_values_muon', [])\n",
        "    \n",
        "    if not shampoo_sv or not muon_sv:\n",
        "        print(\"No singular value data available\")\n",
        "        return\n",
        "    \n",
        "    # Use the last step by default\n",
        "    shampoo_step, shampoo_sv_dict = shampoo_sv[step_idx]\n",
        "    muon_step, muon_sv_dict = muon_sv[step_idx]\n",
        "    \n",
        "    print(f\"Comparing distributions at step {shampoo_step} (Shampoo) vs {muon_step} (Muon)\")\n",
        "    \n",
        "    # Get all layers\n",
        "    layers = list(shampoo_sv_dict.keys())\n",
        "    n_layers = len(layers)\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, n_layers, figsize=(4*n_layers, 10))\n",
        "    if n_layers == 1:\n",
        "        axes = axes.reshape(2, 1)\n",
        "    \n",
        "    fig.suptitle(f'Singular Value Distributions at Step {shampoo_step}', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for i, layer_name in enumerate(layers):\n",
        "        shampoo_svs = shampoo_sv_dict[layer_name]\n",
        "        muon_svs = muon_sv_dict[layer_name]\n",
        "        \n",
        "        # Shampoo distribution\n",
        "        ax1 = axes[0, i]\n",
        "        ax1.hist(shampoo_svs, bins=50, alpha=0.7, color='blue', density=True)\n",
        "        ax1.set_title(f'Shampoo: {layer_name}')\n",
        "        ax1.set_xlabel('Singular Value')\n",
        "        ax1.set_ylabel('Density')\n",
        "        ax1.set_yscale('log')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Muon distribution\n",
        "        ax2 = axes[1, i]\n",
        "        ax2.hist(muon_svs, bins=50, alpha=0.7, color='red', density=True)\n",
        "        ax2.set_title(f'Muon: {layer_name}')\n",
        "        ax2.set_xlabel('Singular Value')\n",
        "        ax2.set_ylabel('Density')\n",
        "        ax2.set_yscale('log')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add statistics\n",
        "        shampoo_mean = np.mean(shampoo_svs)\n",
        "        shampoo_std = np.std(shampoo_svs)\n",
        "        muon_mean = np.mean(muon_svs)\n",
        "        muon_std = np.std(muon_svs)\n",
        "        \n",
        "        ax1.axvline(shampoo_mean, color='darkblue', linestyle='--', linewidth=2, label=f'Mean: {shampoo_mean:.3f}')\n",
        "        ax2.axvline(muon_mean, color='darkred', linestyle='--', linewidth=2, label=f'Mean: {muon_mean:.3f}')\n",
        "        \n",
        "        ax1.legend()\n",
        "        ax2.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_singular_value_distributions(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Singular Value Ratio Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_singular_value_ratios(data):\n",
        "    \"\"\"Plot singular value ratios (condition number, effective rank, etc.).\"\"\"\n",
        "    \n",
        "    shampoo_sv = data.get('singular_values_shampoo', [])\n",
        "    muon_sv = data.get('singular_values_muon', [])\n",
        "    \n",
        "    if not shampoo_sv or not muon_sv:\n",
        "        print(\"No singular value data available\")\n",
        "        return\n",
        "    \n",
        "    # Extract steps\n",
        "    shampoo_steps = [step for step, _ in shampoo_sv]\n",
        "    muon_steps = [step for step, _ in muon_sv]\n",
        "    \n",
        "    # Get layers\n",
        "    layers = list(shampoo_sv[0][1].keys())\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Singular Value Ratio Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Condition number (largest/smallest)\n",
        "    ax1 = axes[0, 0]\n",
        "    for layer_name in layers:\n",
        "        shampoo_cond = []\n",
        "        muon_cond = []\n",
        "        \n",
        "        for _, sv_dict in shampoo_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            cond = svs[0] / svs[-1] if svs[-1] > 0 else np.inf\n",
        "            shampoo_cond.append(cond)\n",
        "        \n",
        "        for _, sv_dict in muon_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            cond = svs[0] / svs[-1] if svs[-1] > 0 else np.inf\n",
        "            muon_cond.append(cond)\n",
        "        \n",
        "        ax1.plot(shampoo_steps, shampoo_cond, label=f'Shampoo: {layer_name}', linewidth=2)\n",
        "        ax1.plot(muon_steps, muon_cond, '--', label=f'Muon: {layer_name}', linewidth=2)\n",
        "    \n",
        "    ax1.set_title('Condition Number (σ₁/σₙ)')\n",
        "    ax1.set_xlabel('Training Step')\n",
        "    ax1.set_ylabel('Condition Number')\n",
        "    ax1.set_yscale('log')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Effective rank (sum of squares / largest squared)\n",
        "    ax2 = axes[0, 1]\n",
        "    for layer_name in layers:\n",
        "        shampoo_eff_rank = []\n",
        "        muon_eff_rank = []\n",
        "        \n",
        "        for _, sv_dict in shampoo_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            eff_rank = np.sum(svs**2) / (svs[0]**2) if svs[0] > 0 else 0\n",
        "            shampoo_eff_rank.append(eff_rank)\n",
        "        \n",
        "        for _, sv_dict in muon_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            eff_rank = np.sum(svs**2) / (svs[0]**2) if svs[0] > 0 else 0\n",
        "            muon_eff_rank.append(eff_rank)\n",
        "        \n",
        "        ax2.plot(shampoo_steps, shampoo_eff_rank, label=f'Shampoo: {layer_name}', linewidth=2)\n",
        "        ax2.plot(muon_steps, muon_eff_rank, '--', label=f'Muon: {layer_name}', linewidth=2)\n",
        "    \n",
        "    ax2.set_title('Effective Rank')\n",
        "    ax2.set_xlabel('Training Step')\n",
        "    ax2.set_ylabel('Effective Rank')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ratio of top 5 to total\n",
        "    ax3 = axes[1, 0]\n",
        "    for layer_name in layers:\n",
        "        shampoo_top5_ratio = []\n",
        "        muon_top5_ratio = []\n",
        "        \n",
        "        for _, sv_dict in shampoo_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            top5_sum = np.sum(svs[:5]**2)\n",
        "            total_sum = np.sum(svs**2)\n",
        "            ratio = top5_sum / total_sum if total_sum > 0 else 0\n",
        "            shampoo_top5_ratio.append(ratio)\n",
        "        \n",
        "        for _, sv_dict in muon_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            top5_sum = np.sum(svs[:5]**2)\n",
        "            total_sum = np.sum(svs**2)\n",
        "            ratio = top5_sum / total_sum if total_sum > 0 else 0\n",
        "            muon_top5_ratio.append(ratio)\n",
        "        \n",
        "        ax3.plot(shampoo_steps, shampoo_top5_ratio, label=f'Shampoo: {layer_name}', linewidth=2)\n",
        "        ax3.plot(muon_steps, muon_top5_ratio, '--', label=f'Muon: {layer_name}', linewidth=2)\n",
        "    \n",
        "    ax3.set_title('Top 5 Singular Values Energy Ratio')\n",
        "    ax3.set_xlabel('Training Step')\n",
        "    ax3.set_ylabel('Energy Ratio')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Decay rate (exponential fit)\n",
        "    ax4 = axes[1, 1]\n",
        "    for layer_name in layers:\n",
        "        shampoo_decay = []\n",
        "        muon_decay = []\n",
        "        \n",
        "        for _, sv_dict in shampoo_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            # Fit exponential decay to singular values\n",
        "            if len(svs) > 1:\n",
        "                x = np.arange(len(svs))\n",
        "                log_svs = np.log(svs + 1e-10)\n",
        "                coeffs = np.polyfit(x, log_svs, 1)\n",
        "                decay_rate = -coeffs[0]  # Negative of slope\n",
        "                shampoo_decay.append(decay_rate)\n",
        "            else:\n",
        "                shampoo_decay.append(0)\n",
        "        \n",
        "        for _, sv_dict in muon_sv:\n",
        "            svs = sv_dict[layer_name]\n",
        "            if len(svs) > 1:\n",
        "                x = np.arange(len(svs))\n",
        "                log_svs = np.log(svs + 1e-10)\n",
        "                coeffs = np.polyfit(x, log_svs, 1)\n",
        "                decay_rate = -coeffs[0]\n",
        "                muon_decay.append(decay_rate)\n",
        "            else:\n",
        "                muon_decay.append(0)\n",
        "        \n",
        "        ax4.plot(shampoo_steps, shampoo_decay, label=f'Shampoo: {layer_name}', linewidth=2)\n",
        "        ax4.plot(muon_steps, muon_decay, '--', label=f'Muon: {layer_name}', linewidth=2)\n",
        "    \n",
        "    ax4.set_title('Singular Value Decay Rate')\n",
        "    ax4.set_xlabel('Training Step')\n",
        "    ax4.set_ylabel('Decay Rate')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_singular_value_ratios(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Metrics vs Singular Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metrics_vs_singular_values(data):\n",
        "    \"\"\"Plot training metrics alongside singular value statistics.\"\"\"\n",
        "    \n",
        "    shampoo_sv = data.get('singular_values_shampoo', [])\n",
        "    muon_sv = data.get('singular_values_muon', [])\n",
        "    shampoo_metrics = data.get('metrics_shampoo', [])\n",
        "    muon_metrics = data.get('metrics_muon', [])\n",
        "    \n",
        "    if not shampoo_sv or not muon_sv or not shampoo_metrics.size or not muon_metrics.size:\n",
        "        print(\"Insufficient data for metrics vs singular values plot\")\n",
        "        return\n",
        "    \n",
        "    # Convert metrics to numpy arrays\n",
        "    shampoo_metrics = np.array(shampoo_metrics)\n",
        "    muon_metrics = np.array(muon_metrics)\n",
        "    \n",
        "    # Extract epochs and accuracies\n",
        "    shampoo_epochs = shampoo_metrics[:, 0]\n",
        "    shampoo_test_acc = shampoo_metrics[:, 4]\n",
        "    muon_epochs = muon_metrics[:, 0]\n",
        "    muon_test_acc = muon_metrics[:, 4]\n",
        "    \n",
        "    # Get singular value steps and compute statistics\n",
        "    shampoo_sv_steps = [step for step, _ in shampoo_sv]\n",
        "    muon_sv_steps = [step for step, _ in muon_sv]\n",
        "    \n",
        "    # Compute average condition number across layers\n",
        "    shampoo_avg_cond = []\n",
        "    muon_avg_cond = []\n",
        "    \n",
        "    for _, sv_dict in shampoo_sv:\n",
        "        layer_conds = []\n",
        "        for layer_name, svs in sv_dict.items():\n",
        "            cond = svs[0] / svs[-1] if svs[-1] > 0 else np.inf\n",
        "            layer_conds.append(cond)\n",
        "        shampoo_avg_cond.append(np.mean(layer_conds))\n",
        "    \n",
        "    for _, sv_dict in muon_sv:\n",
        "        layer_conds = []\n",
        "        for layer_name, svs in sv_dict.items():\n",
        "            cond = svs[0] / svs[-1] if svs[-1] > 0 else np.inf\n",
        "            layer_conds.append(cond)\n",
        "        muon_avg_cond.append(np.mean(layer_conds))\n",
        "    \n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "    fig.suptitle('Training Metrics vs Singular Value Statistics', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Test accuracy over epochs\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(shampoo_epochs, shampoo_test_acc, label='Shampoo', linewidth=3, color='blue')\n",
        "    ax1.plot(muon_epochs, muon_test_acc, label='Muon', linewidth=3, color='red')\n",
        "    ax1.set_title('Test Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Test Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Average condition number over steps\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.plot(shampoo_sv_steps, shampoo_avg_cond, label='Shampoo', linewidth=3, color='blue')\n",
        "    ax2.plot(muon_sv_steps, muon_avg_cond, label='Muon', linewidth=3, color='red')\n",
        "    ax2.set_title('Average Condition Number')\n",
        "    ax2.set_xlabel('Training Step')\n",
        "    ax2.set_ylabel('Condition Number')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Correlation plot\n",
        "    ax3 = axes[1, 0]\n",
        "    # Interpolate condition numbers to match epoch times\n",
        "    shampoo_cond_interp = np.interp(shampoo_epochs, shampoo_sv_steps, shampoo_avg_cond)\n",
        "    muon_cond_interp = np.interp(muon_epochs, muon_sv_steps, muon_avg_cond)\n",
        "    \n",
        "    ax3.scatter(shampoo_cond_interp, shampoo_test_acc, label='Shampoo', alpha=0.7, s=50)\n",
        "    ax3.scatter(muon_cond_interp, muon_test_acc, label='Muon', alpha=0.7, s=50)\n",
        "    ax3.set_title('Test Accuracy vs Condition Number')\n",
        "    ax3.set_xlabel('Condition Number')\n",
        "    ax3.set_ylabel('Test Accuracy')\n",
        "    ax3.set_xscale('log')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Final comparison\n",
        "    ax4 = axes[1, 1]\n",
        "    final_shampoo_acc = shampoo_test_acc[-1]\n",
        "    final_muon_acc = muon_test_acc[-1]\n",
        "    final_shampoo_cond = shampoo_avg_cond[-1]\n",
        "    final_muon_cond = muon_avg_cond[-1]\n",
        "    \n",
        "    x = ['Shampoo', 'Muon']\n",
        "    acc_values = [final_shampoo_acc, final_muon_acc]\n",
        "    cond_values = [final_shampoo_cond, final_muon_cond]\n",
        "    \n",
        "    ax4_twin = ax4.twinx()\n",
        "    \n",
        "    bars1 = ax4.bar(x, acc_values, alpha=0.7, color=['blue', 'red'], label='Test Accuracy')\n",
        "    bars2 = ax4_twin.bar(x, cond_values, alpha=0.7, color=['lightblue', 'lightcoral'], label='Condition Number')\n",
        "    \n",
        "    ax4.set_title('Final Performance Comparison')\n",
        "    ax4.set_ylabel('Test Accuracy')\n",
        "    ax4_twin.set_ylabel('Condition Number')\n",
        "    ax4_twin.set_yscale('log')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, val in zip(bars1, acc_values):\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{val:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    for bar, val in zip(bars2, cond_values):\n",
        "        ax4_twin.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1, \n",
        "                     f'{val:.1e}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_metrics_vs_singular_values(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_summary_statistics(data):\n",
        "    \"\"\"Print comprehensive summary statistics.\"\"\"\n",
        "    \n",
        "    shampoo_sv = data.get('singular_values_shampoo', [])\n",
        "    muon_sv = data.get('singular_values_muon', [])\n",
        "    shampoo_metrics = data.get('metrics_shampoo', [])\n",
        "    muon_metrics = data.get('metrics_muon', [])\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if shampoo_sv and muon_sv:\n",
        "        # Get final singular values\n",
        "        final_shampoo_sv = shampoo_sv[-1][1]\n",
        "        final_muon_sv = muon_sv[-1][1]\n",
        "        \n",
        "        print(\"\\nFINAL SINGULAR VALUE STATISTICS:\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        for layer_name in final_shampoo_sv.keys():\n",
        "            shampoo_svs = final_shampoo_sv[layer_name]\n",
        "            muon_svs = final_muon_sv[layer_name]\n",
        "            \n",
        "            print(f\"\\nLayer: {layer_name}\")\n",
        "            print(f\"  Shampoo:\")\n",
        "            print(f\"    - Largest σ: {shampoo_svs[0]:.6f}\")\n",
        "            print(f\"    - Smallest σ: {shampoo_svs[-1]:.6f}\")\n",
        "            print(f\"    - Condition #: {shampoo_svs[0]/shampoo_svs[-1]:.2e}\")\n",
        "            print(f\"    - Mean σ: {np.mean(shampoo_svs):.6f}\")\n",
        "            print(f\"    - Std σ: {np.std(shampoo_svs):.6f}\")\n",
        "            print(f\"    - Effective rank: {np.sum(shampoo_svs**2)/(shampoo_svs[0]**2):.2f}\")\n",
        "            \n",
        "            print(f\"  Muon:\")\n",
        "            print(f\"    - Largest σ: {muon_svs[0]:.6f}\")\n",
        "            print(f\"    - Smallest σ: {muon_svs[-1]:.6f}\")\n",
        "            print(f\"    - Condition #: {muon_svs[0]/muon_svs[-1]:.2e}\")\n",
        "            print(f\"    - Mean σ: {np.mean(muon_svs):.6f}\")\n",
        "            print(f\"    - Std σ: {np.std(muon_svs):.6f}\")\n",
        "            print(f\"    - Effective rank: {np.sum(muon_svs**2)/(muon_svs[0]**2):.2f}\")\n",
        "            \n",
        "            # Comparison\n",
        "            cond_ratio = (shampoo_svs[0]/shampoo_svs[-1]) / (muon_svs[0]/muon_svs[-1])\n",
        "            print(f\"  Comparison:\")\n",
        "            print(f\"    - Condition # ratio (Shampoo/Muon): {cond_ratio:.2f}\")\n",
        "    \n",
        "    if shampoo_metrics.size and muon_metrics.size:\n",
        "        shampoo_metrics = np.array(shampoo_metrics)\n",
        "        muon_metrics = np.array(muon_metrics)\n",
        "        \n",
        "        print(\"\\n\\nFINAL TRAINING METRICS:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Shampoo final test accuracy: {shampoo_metrics[-1, 4]:.4f}\")\n",
        "        print(f\"Muon final test accuracy: {muon_metrics[-1, 4]:.4f}\")\n",
        "        print(f\"Difference (Shampoo - Muon): {shampoo_metrics[-1, 4] - muon_metrics[-1, 4]:+.4f}\")\n",
        "        \n",
        "        print(f\"\\nShampoo final train accuracy: {shampoo_metrics[-1, 2]:.4f}\")\n",
        "        print(f\"Muon final train accuracy: {muon_metrics[-1, 2]:.4f}\")\n",
        "        print(f\"Difference (Shampoo - Muon): {shampoo_metrics[-1, 2] - muon_metrics[-1, 2]:+.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "print_summary_statistics(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Instructions\n",
        "\n",
        "1. **Run the dual training experiment** first using `main_dual_training.py`\n",
        "2. **Execute this notebook** to visualize the results\n",
        "3. **Modify the analysis** by uncommenting interactive sections\n",
        "4. **Export results** by uncommenting the export function\n",
        "\n",
        "### Key Insights to Look For:\n",
        "\n",
        "- **Condition Number**: Lower condition numbers indicate better-conditioned weight matrices\n",
        "- **Effective Rank**: Higher effective rank suggests better utilization of the parameter space\n",
        "- **Singular Value Decay**: Steeper decay may indicate better regularization\n",
        "- **Distribution Shape**: Different optimizers may produce different singular value distributions\n",
        "- **Correlation with Performance**: How singular value statistics correlate with test accuracy\n",
        "\n",
        "### Expected File Structure:\n",
        "```\n",
        "logs/\n",
        "└── dual_training_<uuid>/\n",
        "    ├── singular_values_shampoo.pkl\n",
        "    ├── singular_values_muon.pkl\n",
        "    ├── metrics_shampoo.npy\n",
        "    ├── metrics_muon.npy\n",
        "    ├── config.pt\n",
        "    ├── model_shampoo.pt\n",
        "    └── model_muon.pt\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
